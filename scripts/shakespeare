#!/usr/bin/env python
import argparse
import sys,os
import cPickle as pickle
from shakespeare.content_sources import arxiv, bibtex, rss
from shakespeare import *


#add command line options for sources, output prefs, database of "good" keywords
parser = argparse.ArgumentParser()
parser.add_argument('-o','--output', help='output file name. only supports markdown right now.',dest ='output',default=None)
parser.add_argument('-b','--bibtex', help='bibtex files to fetch',dest='bibfiles', nargs='*',default=list())
parser.add_argument('-j','--journals', help='journals to fetch. Currently supports {}.'.format(' '.join(rss.rss_feeds.keys())),
                    nargs='*',dest='journals',default=list())
parser.add_argument('-a','--arXiv', help='arXiv categories to fetch',
                  nargs='*',dest='arXiv',default=list())
parser.add_argument('--all_sources', help='flag to search from all sources.',action ='store_true')
parser.add_argument('--all_good_sources', help='flag to search from good sources. Specfied in your config file.',action ='store_true')
parser.add_argument('--train', help='flag to train. All sources beside "--train-input-good" are treated as bad/irrelevant papers',action ='store_true')
parser.add_argument('-g','--train_input_good', help='bibtex file containing relevant articles.',dest ='good_source',default=None)
parser.add_argument('-m','--method', help='Methods to try to find relevent papers. Right now, only all, title, author, and abstract are valid fields',
                    dest='method',default='title')
parser.add_argument('-k', '--knowledge',
                    help='path to database containing information about good and bad keywords. \
                          If you are training, you must specifiy this, as it will be where your output is written ',
                    dest='knowledge',default=None)
parser.add_argument('--overwrite-knowledge', help='flag to overwrite knowledge,if training',action ='store_true',default=False, dest='overwrite_knowledge')
parser.add_argument('--feedback', help='flag to give feedback after sorting content',action ='store_true',default=False, dest='feedback')
parser.add_argument('--review_all', help='review all the new selections. Otherwise, you will only review the good selections',action ='store_true',default=False, dest='review_all')
args = parser.parse_args(sys.argv[1:])

if  not args.method in ['title','abstract','author, all']:
        print("Invalid method. Options are title, abstract, author, and all")
        exit()

method = args.method

#Set up training if that's what we're doing
if args.train:

    #check to make sure we have a good training input
    if args.good_source is None:
        print("When training, you must specify one good source")
        exit()
    if not os.path.exists(args.good_source):
        print("Specified training input does not exist")
        exit()
    if not os.path.isfile(args.good_source):
        print("Specified training input is not a file")
        exit()
    if not os.path.splitext(args.good_source)[1] == '.bib' :
        print("Training input must be in bibtex format")
        exit()

    #load the existing knowledge
    nb,kw,knowledge = load_knowledge(args.knowledge)
    if args.overwrite_knowledge:
        nb=None
        kw=list()

    good_content = get_content([bibtex.BibTex(args.good_source)])

    if args.all_sources:
        bad_content = get_content([arxiv.ArXiv(cat) for cat in arxiv.arxiv_cats] +
                                  [rss.JournalFeed(journal) for journal in rss.rss_feeds.keys()])
    else:
        bad_content = get_content([arxiv.ArXiv(cat) for cat in args.arXiv] +
                                  [bibtex.BibTex(bibfile) for bibfile in args.bibfiles] +
                                  [rss.JournalFeed(journal) for journal in args.journals])

    #train, and write out knowledge (naive_bayes class and keywords)
    nb, kw = train(good_content,bad_content,method,naive_bayes=nb, keywords=kw)
    pickle.dump(nb,open(knowledge+'/nb.p','w'))
    pickle.dump(kw,open(knowledge+'/kw.p','w'))

#we are filtering new content through our existing knowledge
else:

    #load the old knowledge
    nb,kw,knowledge = load_knowledge(args.knowledge)
    if args.all_sources:
        sources = [arxiv.ArXiv(cat) for cat in arxiv.arxiv_cats] + \
                  [rss.JournalFeed(journal) for journal in rss.rss_feeds.keys()]
    elif args.all_good_sources:
        arxiv_cats = ['cond-mat','stat']
        journals = ['science','nature','small','prl','pnas',
                    'physreve','physrevx','acsnano',
                    'advmat','jchemphysb','natphys',
                    'natmat','natnano','langmuir']

        sources = [arxiv.ArXiv(cat) for cat in arxiv_cats] + \
                  [rss.JournalFeed(journal) for journal in journals]
    else:
        sources = [arxiv.ArXiv(cat) for cat in args.arXiv] + \
                  [ bibtex.BibTex (bibfile) for bibfile in args.bibfiles] + \
                  [rss.JournalFeed(journal) for journal in args.journals]

    new_content = get_content(sources)
    good_content = filter_content(new_content,method,nb,kw)
    print("Fraction of good new content: {!r}".format(len(good_content)*1.0/len(new_content)))
    print("total  content parsed: {!r}".format(len(new_content)))

    if (args.output):
        to_markdown(good_content,args.output)
    else:
        pass
        #print(good_content)

    if(args.feedback):
        human_class, reviewed_content = review_content(good_content,new_content,method,args.review_all)
        good_content = [entry for cat,entry in zip(human_class,reviewed_content) if cat=='good']
        bad_content = [entry for cat,entry in zip(human_class,reviewed_content) if cat=='bad']
        nb, kw = train(good_content,bad_content,method,naive_bayes=nb, keywords=kw)
        pickle.dump(nb,open(knowledge+'/nb.p','w'))
        pickle.dump(kw,open(knowledge+'/kw.p','w'))
